{
  "hash": "0362a4be2725ec20c97347f192c0645c",
  "result": {
    "markdown": "\n\n\n\n# Graph (convolutional) neural networks\n\nGraph neural networks (GNN) is a young representative of the deep neural network family but is receiving more and more attention in the last years because of their ability to process non-Euclidean data such as graphs.\n\nCurrently there is no R package for GNNs available. However, we can use the 'reticulate' package (@reticulate) to use the python packages 'torch' and 'torch_geometric' (@NEURIPS2019_9015, 2019; @Fey_Lenssen_2019).\n\nThe following example was mostly adapted from the 'Node Classification with Graph Neural Networks' example from the torch_geometric documentation (<https://pytorch-geometric.readthedocs.io/en/latest/notes/colabs.html>).\n\nThe dataset is also provided by the 'torch_geometric' package and consists of molecules presented as graphs and the task is to predict whether HIV virus replication is inhibited by the molecule or not (classification, binary classification).\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-1_e7eebd7abb606815cdf70f0f52548e73'}\n\n```{.r .cell-code}\nlibrary(reticulate)\n# Load python packages torch and torch_geometric via the reticulate R package\ntorch = import(\"torch\") \ntorch_geometric = import(\"torch_geometric\")\n\n# helper functions from the torch_geometric modules\nGCNConv = torch_geometric$nn$GCNConv\nglobal_mean_pool = torch_geometric$nn$global_mean_pool\n\n\n# Download the MUTAG TUDataset\ndataset = torch_geometric$datasets$TUDataset(root='data/TUDataset', \n                                             name='MUTAG')\ndataloader = torch_geometric$loader$DataLoader(dataset, \n                                               batch_size=64L,\n                                               shuffle=TRUE)\n\n# Create the model with a python class\n# There are two classes in the response variable\nGCN = PyClass(\n  \"GCN\", \n   inherit = torch$nn$Module, \n   defs = list(\n       `__init__` = function(self, hidden_channels) {\n         super()$`__init__`()\n         torch$manual_seed(42L)\n         self$conv = GCNConv(dataset$num_node_features, hidden_channels)\n         self$linear = torch$nn$Linear(hidden_channels, dataset$num_classes)\n         NULL\n       },\n       forward = function(self, x, edge_index, batch) {\n         x = self$conv(x, edge_index)\n         x = x$relu()\n         x = global_mean_pool(x, batch)\n         \n         x = torch$nn$functional$dropout(x, p = 0.5, training=self$training)\n         x = self$linear(x)\n         return(x)\n       }\n   ))\n```\n:::\n\n\nTraining loop:\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-2_d04596925b794b5fe6d260fb3947b795'}\n\n```{.r .cell-code}\n# create model object\nmodel = GCN(hidden_channels = 64L)\n\n# get optimizer and loss function\noptimizer = torch$optim$Adamax(model$parameters(), lr = 0.01)\nloss_func = torch$nn$CrossEntropyLoss()\n\n# set model into training mode (because of the dropout layer)\nmodel$train()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGCN(\n  (conv): GCNConv(7, 64)\n  (linear): Linear(in_features=64, out_features=2, bias=True)\n)\n```\n:::\n\n```{.r .cell-code}\n# train model\nfor(e in 1:50) {\n  iterator = reticulate::as_iterator(dataloader)\n  coro::loop(for (b in iterator) { \n     pred = model(b$x, b$edge_index, b$batch)\n     loss = loss_func(pred, b$y)\n     loss$backward()\n     optimizer$step()\n     optimizer$zero_grad()\n  })\n  if(e %% 10 ==0) cat(paste0(\"Epoch: \",e,\" Loss: \", round(loss$item()[1], 4), \"\\n\"))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch: 10 Loss: 0.6151\nEpoch: 20 Loss: 0.6163\nEpoch: 30 Loss: 0.5745\nEpoch: 40 Loss: 0.5362\nEpoch: 50 Loss: 0.5829\n```\n:::\n:::\n\n\nMake predictions:\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-3_69e8a9a9aba2b3812887fe0182f7f768'}\n\n```{.r .cell-code}\npreds = list()\ntest = torch_geometric$loader$DataLoader(dataset, batch_size=64L,shuffle=FALSE)\niterator = reticulate::as_iterator(test)\nmodel$eval()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGCN(\n  (conv): GCNConv(7, 64)\n  (linear): Linear(in_features=64, out_features=2, bias=True)\n)\n```\n:::\n\n```{.r .cell-code}\ncounter = 1\ncoro::loop(for (b in iterator) {\n  preds[[counter]] = model(b$x, b$edge_index, b$batch)\n  counter <<- counter + 1\n  })\nhead(torch$concat(preds)$sigmoid()$data$cpu()$numpy(), n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]      [,2]\n[1,] 0.3076028 0.6427078\n[2,] 0.4121239 0.5515330\n[3,] 0.4119514 0.5516798\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-4_7943ac072d0f9e816291aa6813c13d8d'}\n\n```{.python .cell-code}\n# Load python packages torch and torch_geometric via the reticulate R package\nimport torch\nimport torch_geometric\n\n# helper functions from the torch_geometric modules\nGCNConv = torch_geometric.nn.GCNConv\nglobal_mean_pool = torch_geometric.nn.global_mean_pool\n\n\n# Download the MUTAG TUDataset\ndataset = torch_geometric.datasets.TUDataset(root='data/TUDataset', \n                                             name='MUTAG')\ndataloader = torch_geometric.loader.DataLoader(dataset, \n                                               batch_size=64,\n                                               shuffle=True)\n\n# Create the model with a python class\n# There are two classes in the response variable\nclass GCN(torch.nn.Module):\n    def __init__(self, hidden_channels):\n         super().__init__()\n         torch.manual_seed(42)\n         self.conv = GCNConv(dataset.num_node_features, hidden_channels)\n         self.linear = torch.nn.Linear(hidden_channels, dataset.num_classes)\n         \n    def forward(self, x, edge_index, batch):\n        x = self.conv(x, edge_index)\n        x = x.relu()\n        x = global_mean_pool(x, batch)\n        x = torch.nn.functional.dropout(x, p = 0.5, training=self.training)\n        x = self.linear(x)\n        return x\n```\n:::\n\n\nTraining loop:\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-5_d751f3f3ccb1f7e83009b7786ddbc559'}\n\n```{.python .cell-code}\n# create model object\nmodel = GCN(hidden_channels = 64)\n\n# get optimizer and loss function\noptimizer = torch.optim.Adamax(model.parameters(), lr = 0.01)\nloss_func = torch.nn.CrossEntropyLoss()\n\n# set model into training mode (because of the dropout layer)\nmodel.train()\n\n# train model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGCN(\n  (conv): GCNConv(7, 64)\n  (linear): Linear(in_features=64, out_features=2, bias=True)\n)\n```\n:::\n\n```{.python .cell-code}\nfor e in range(50):\n  for b in dataloader:\n  \n    pred = model(b.x, b.edge_index, b.batch)\n    loss = loss_func(pred, b.y)\n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n     \n  if e % 10 ==0:\n    print(\"Epoch: \", e ,\" Loss: \", loss.item(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch:  0  Loss:  0.6617005467414856 \n\nEpoch:  10  Loss:  0.614981472492218 \n\nEpoch:  20  Loss:  0.6161867380142212 \n\nEpoch:  30  Loss:  0.5802667737007141 \n\nEpoch:  40  Loss:  0.5124867558479309 \n```\n:::\n:::\n\n\nMake predictions:\n\n\n::: {.cell hash='gnn_cache/html/unnamed-chunk-6_ef2d307f41fa7b047bd0331824bcce47'}\n\n```{.python .cell-code}\npreds = []\ntest = torch_geometric.loader.DataLoader(dataset, batch_size=64,shuffle=False)\nmodel.eval()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGCN(\n  (conv): GCNConv(7, 64)\n  (linear): Linear(in_features=64, out_features=2, bias=True)\n)\n```\n:::\n\n```{.python .cell-code}\ncounter = 1\nfor b in test:\n  preds.append( model(b.x, b.edge_index, b.batch) )\n  \n  \ntorch.concat(preds).sigmoid().data.cpu().numpy()[0:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[0.30760282, 0.64270777],\n       [0.41212386, 0.551533  ],\n       [0.4119514 , 0.5516798 ],\n       [0.29887193, 0.650517  ],\n       [0.48894534, 0.48584774],\n       [0.4310807 , 0.5360305 ],\n       [0.31375578, 0.63721913],\n       [0.34597102, 0.6093393 ],\n       [0.50279325, 0.4740774 ],\n       [0.30924183, 0.6412629 ]], dtype=float32)\n```\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}