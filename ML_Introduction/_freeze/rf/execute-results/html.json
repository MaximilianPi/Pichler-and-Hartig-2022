{
  "hash": "1e690fcddf1dc137474da985f4e0da77",
  "result": {
    "markdown": "\n\n\n# Random forest\n\nThe random forest (RF) algorithm is probably one of the most famous ML algorithms, and not without reason. Compared to other well performing algorithms, the RF algorithm has only a few hyper-parameters and because of the bagging and the random sampling of available variables in for the node splits, it has a well working internal complexity adaption.\n\nIn the following, we use the 'ranger' package (@ranger).\n\n## Classification\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-1_3bbdef14bd092518f9c9a8f2d5a4c107'}\n\n```{.r .cell-code}\nlibrary(ranger)\nX = iris[,1:4]\nY = iris[,5,drop=FALSE]\ndata = cbind(Y, X)\n\nrf = ranger(Species~., data = data, probability = TRUE, importance = \"impurity\")\n```\n:::\n\n\nShow feature importances:\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-2_9405cc5939c839d06d3cf3766399aac8'}\n\n```{.r .cell-code}\nimportance(rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n    9.249145     1.219569    43.129082    42.020543 \n```\n:::\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-3_9bb3341e025da926c257e936f6c71410'}\n\n```{.r .cell-code}\nhead(predict(rf, data = data)$predictions, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     setosa versicolor virginica\n[1,]  1.000      0.000         0\n[2,]  0.998      0.002         0\n[3,]  1.000      0.000         0\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-4_7a81897a6d80972e81603985e062fdec'}\n\n```{.python .cell-code}\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\nX = scale(iris.data)\nY = iris.target\n\nmodel = RandomForestClassifier().fit(X, Y)\n```\n:::\n\n\nFeature importance\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-5_6876e0130bc552f42afc51317f1b3ab3'}\n\n```{.python .cell-code}\nprint(model.feature_importances_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[0.10941572 0.0180583  0.42478094 0.44774504]\n```\n:::\n:::\n\n\nMake predictions:\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-6_01bb8a6c238501c27ecc385a04b1df8c'}\n\n```{.python .cell-code}\nmodel.predict_proba(X)[0:10,:]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.]])\n```\n:::\n:::\n\n:::\n\n## Regression\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-7_ec7691ccdae8fdf58a1ee6b713a3bce8'}\n\n```{.r .cell-code}\nlibrary(ranger)\nX = iris[,2:4]\ndata = cbind(iris[,1,drop=FALSE], X)\n\nrf = ranger(Sepal.Length~., data = data, importance = \"impurity\")\n```\n:::\n\n\nShow feature importances:\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-8_f60198ab98731659117928df7e03f843'}\n\n```{.r .cell-code}\nimportance(rf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Sepal.Width Petal.Length  Petal.Width \n    12.23700     45.33879     37.60782 \n```\n:::\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-9_d9119be406c792584858da772a76a61b'}\n\n```{.r .cell-code}\nhead(predict(rf, data = data)$predictions, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.107437 4.769263 4.659477\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-10_9ff91a9a3da987d51c9fff4a49218c23'}\n\n```{.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\ndata = iris.data\nX = scale(data[:,1:4])\nY = data[:,0]\n\nmodel = RandomForestRegressor().fit(X, Y)\n```\n:::\n\n\nFeature importance:\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-11_2e3b2edeee2868626d73a3403ee96e26'}\n\n```{.python .cell-code}\nprint(model.feature_importances_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[0.08116014 0.85334203 0.06549783]\n```\n:::\n:::\n\n\nMake predictions:\n\n\n::: {.cell hash='rf_cache/html/unnamed-chunk-12_4f3f7843d386ad6ad3fc826d54ffbff8'}\n\n```{.python .cell-code}\nmodel.predict(X)[0:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.105     , 4.825     , 4.61075   , 4.75075   , 5.014     ,\n       5.438     , 4.81933333, 5.05696667, 4.52      , 4.8435    ])\n```\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}