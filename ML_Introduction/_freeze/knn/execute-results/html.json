{
  "hash": "669d5f5417ec70e985d9e24bdbc1645b",
  "result": {
    "markdown": "\n\n\n# k-nearest-neighbor\n\nThe k-nearest-neighbor algorithm doesn't really learn from the data, predictions for new observations are made based on the class affiliation (or response value) of the nearest neighbors, e.g. by majority voting or averaging. The nearest neighbors are found by calculating the distance of the new observation to all observations in the train dataset.\n\nIn the following we use the 'kknn' package (@kknn). Different to other ML packages we can provide here already the test dataset in the fit function.\n\n## Classification\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-1_e027ebc54b24924f11648bef20f73286'}\n\n```{.r .cell-code}\nlibrary(kknn)\nX = scale(iris[,1:4])\nY = iris[,5,drop=FALSE]\ndata = cbind(Y, X)\n\nknn = kknn(Species~., train = data, test = data) \n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-2_b0288c2db6046f627e41d9d5991681a9'}\n\n```{.r .cell-code}\nhead(knn$prob, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     setosa versicolor virginica\n[1,]      1          0         0\n[2,]      1          0         0\n[3,]      1          0         0\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-3_e7fda25427bd48c113d7d793eab4cf9c'}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\nX = scale(iris.data)\nY = iris.target\n\nmodel = KNeighborsClassifier().fit(X, Y)\n\n# Make predictions:\n\nmodel.predict_proba(X)[0:10,:]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.]])\n```\n:::\n:::\n\n:::\n\n## Regression\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-4_eee6529d93b92d805e3fea4d63150556'}\n\n```{.r .cell-code}\nlibrary(e1071)\nX = scale(iris[,2:4])\ndata = cbind(iris[,1,drop=FALSE], X)\n\nknn = kknn(Sepal.Length~., train = data, test = data) \n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-5_c3cbdab6fd433aac69d56faba522d6a0'}\n\n```{.r .cell-code}\nhead(predict(knn), n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.188492 4.739986 4.685332\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-6_41b00fbb92181917c171ba4ae00434da'}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\ndata = iris.data\nX = scale(data[:,1:4])\nY = data[:,0]\n\nmodel = KNeighborsRegressor().fit(X, Y)\n\n# Make predictions:\n\nmodel.predict(X)[0:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.18, 4.78, 4.68, 4.76, 4.98, 5.34, 5.06, 5.1 , 4.7 , 4.8 ])\n```\n:::\n:::\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}