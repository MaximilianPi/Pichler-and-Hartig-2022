{
  "hash": "b93cc420182441d86f61891bed73ad3a",
  "result": {
    "markdown": "# k-nearest-neighbor\n\n\n\n\n\n\nThe k-nearest-neighbor algorithm doesn't really learn from the data, predictions for new observations are made based on the class affiliation (or response value) of the nearest neighbors, e.g. by majority voting or averaging. The nearest neighbors are found by calculating the distance of the new observation to all observations in the train dataset.\n\nIn the following we use the 'kknn' package (@kknn) (Python: 'scikit-learn' (@scikit-learn), Julia: 'MLJ' (@anthony_blaom_2019_3541506)). Different to other ML packages we can provide here already the test dataset in the fit function.\n\n## Classification\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-2_4fb0b73c2b221d9c2ec0684da43eac92'}\n\n```{.r .cell-code}\nlibrary(kknn)\nX = scale(iris[,1:4])\nY = iris[,5,drop=FALSE]\ndata = cbind(Y, X)\n\nknn = kknn(Species~., train = data, test = data) \n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-3_e269963aad949e40c3c42a2853ff2b94'}\n\n```{.r .cell-code}\nhead(knn$prob, n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     setosa versicolor virginica\n[1,]      1          0         0\n[2,]      1          0         0\n[3,]      1          0         0\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-4_3499bd0e54ae77adf9f09a1e44fcf1c5'}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\nX = scale(iris.data)\nY = iris.target\n\nmodel = KNeighborsClassifier().fit(X, Y)\n\n# Make predictions:\n\nmodel.predict_proba(X)[0:10,:]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.]])\n```\n:::\n:::\n\n\n\n### Julia\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-5_d39f2e9184fe0d2e566bb6c66fad18ee'}\n\n```{.julia .cell-code}\nimport StatsBase;\nusing MLJ;\nkNN_classifier = @load KNNClassifier pkg=NearestNeighborModels;\nusing RDatasets;\nusing StatsBase;\nusing DataFrames;\n```\n:::\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-6_2e155941c4bdeb2db114f490cf05259a'}\n\n```{.julia .cell-code}\niris = dataset(\"datasets\", \"iris\");\nX = mapcols(StatsBase.zscore, iris[:, 1:4]);\nY = iris[:, 5];\n```\n:::\n\n\nModels:\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-7_49c2ddc508c055aea2b842cac2478d30'}\n\n```{.julia .cell-code}\nmodel = fit!(machine(kNN_classifier(), X, Y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntrained Machine; caches model-specific representations of data\n  model: KNNClassifier(K = 5, …)\n  args: \n    1:\tSource @082 ⏎ Table{AbstractVector{Continuous}}\n    2:\tSource @399 ⏎ AbstractVector{Multiclass{3}}\n```\n:::\n:::\n\n\nPredictions:\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-8_4c8a5837cacd63d133bb77af2eb7c262'}\n\n```{.julia .cell-code}\nMLJ.predict(model, X)[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5-element CategoricalDistributions.UnivariateFiniteVector{Multiclass{3}, String, UInt8, Float64}:\n UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n UnivariateFinite{Multiclass{3}}(setosa=>1.0, versicolor=>0.0, virginica=>0.0)\n```\n:::\n:::\n\n\n\n:::\n\n## Regression\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-9_de5b28c582489c6a574473524e73a91a'}\n\n```{.r .cell-code}\nlibrary(e1071)\nX = scale(iris[,2:4])\ndata = cbind(iris[,1,drop=FALSE], X)\n\nknn = kknn(Sepal.Length~., train = data, test = data) \n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-10_c031f24542d24400dcbc0e6ddc073f54'}\n\n```{.r .cell-code}\nhead(predict(knn), n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.188492 4.739986 4.685332\n```\n:::\n:::\n\n\n### Python\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-11_bacb08fbac24654b5d627d5b402bb7cb'}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\ndata = iris.data\nX = scale(data[:,1:4])\nY = data[:,0]\n\nmodel = KNeighborsRegressor().fit(X, Y)\n\n# Make predictions:\n\nmodel.predict(X)[0:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.18, 4.78, 4.68, 4.76, 4.98, 5.34, 5.06, 5.1 , 4.7 , 4.8 ])\n```\n:::\n:::\n\n\n### Julia\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-12_5c92bbbfaa8e47c9c0df8dc48a406a01'}\n\n```{.julia .cell-code}\nimport StatsBase;\nusing MLJ;\nkNN_regressor =  @load KNNRegressor pkg=NearestNeighborModels;\nusing RDatasets;\nusing DataFrames;\n```\n:::\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-13_87a7c581e877b89fbab95b6a131fc295'}\n\n```{.julia .cell-code}\niris = dataset(\"datasets\", \"iris\");\nX = mapcols(StatsBase.zscore, iris[:, 2:4]);\nY = iris[:, 1];\n```\n:::\n\n\nModel:\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-14_e23bfbd4b08917605697044efdc637fb'}\n\n```{.julia .cell-code}\nmodel = fit!(machine(kNN_regressor(), X, Y))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntrained Machine; caches model-specific representations of data\n  model: KNNRegressor(K = 5, …)\n  args: \n    1:\tSource @112 ⏎ Table{AbstractVector{Continuous}}\n    2:\tSource @138 ⏎ AbstractVector{Continuous}\n```\n:::\n:::\n\n\nPredictions:\n\n\n::: {.cell hash='knn_cache/html/unnamed-chunk-15_d797fc3bb36ac721bad40de3872d4f2b'}\n\n```{.julia .cell-code}\nMLJ.predict(model, X)[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5-element Vector{Float64}:\n 5.18\n 4.779999999999999\n 4.68\n 4.82\n 5.0200000000000005\n```\n:::\n:::\n\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}