{
  "hash": "86d3d5764035b2ec5667b29a79bf9ab5",
  "result": {
    "markdown": "\n\n\n# Ridge, LASSO, and elastic-net regression\n\nWe can use the 'glmnet' R package (@glmnet) for Ridge, LASSO, or elastic-net regularization. The 'glmnet' package supports different response families including 'gaussian', 'binomial' and 'Poisson'. The strength of the regularization is set by the 'lambda' argument ($\\lambda$) and the weighting between Ridge and LASSO regularization by the 'alpha' parameter ($\\alpha$):\n\n\n$$\n\\lambda*[(1 - \\alpha)\\|\\beta\\|_1 + \\alpha\\|\\beta||^2]\n$$ Setting alpha = 0 turns off the LASSO and alpha = 1 the Ridge. Alphas between (0,1) will use both regularization types, turning the model into an elastic-net regularization.\n\n\nWhen using regularization, it is important to scale all features otherwise effects for features that are on a larger scale are stronger regularized.\n\n## Classification\n\nBuild models (for regularization it is important to scale the features):\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-1_2023293809a962eb879253ba7e37b18d'}\n\n```{.r .cell-code}\nlibrary(glmnet)\nX = scale(iris[,1:4])\nY = iris$Species\n\n# Ridge:\nridge = glmnet(X, Y, family = \"multinomial\", alpha = 0, lambda = 0.01)\n\n# LASSO:\nlasso = glmnet(X, Y, family = \"multinomial\", alpha = 1, lambda = 0.01)\n\n# Elastic-net:\nelastic = glmnet(X, Y, family = \"multinomial\", alpha = 0.5, lambda = 0.01)\n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-2_fa133082bd38237c6b1f304d4b403119'}\n\n```{.r .cell-code}\nhead(predict(lasso, newx = X, type = \"response\")[,,1], n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        setosa versicolor    virginica\n[1,] 0.9858987 0.01410131 3.438452e-09\n[2,] 0.9668897 0.03311031 1.397684e-08\n[3,] 0.9815369 0.01846312 5.279315e-09\n```\n:::\n:::\n\n\n### Python\n\nIn the sklearn implementation the regularization strength parameter 'C' corresponds to the lambda parameter from glmnet:\n\n\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-4_1488f0ff605fdd1b105104b68779e29b'}\n\n```{.python .cell-code}\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\nX = scale(iris.data)\nY = iris.target\n\n\n# Ridge:\nridge = LogisticRegression(multi_class='multinomial', \n                           penalty = \"l2\", \n                           C = 0.01, \n                           solver=\"saga\")\nridge.fit(X, Y)\n\n# LASSO:\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogisticRegression(C=0.01, multi_class='multinomial', solver='saga')\n```\n:::\n\n```{.python .cell-code}\nlasso = LogisticRegression(multi_class='multinomial', \n                           penalty = \"l1\", \n                           C = 0.01, \n                           solver=\"saga\")\nlasso.fit(X, Y)\n\n# Elastic-net:\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogisticRegression(C=0.01, multi_class='multinomial', penalty='l1',\n                   solver='saga')\n```\n:::\n\n```{.python .cell-code}\nelastic = LogisticRegression(multi_class='multinomial', \n                             penalty = \"elasticnet\", \n                             C = 0.01, \n                             l1_ratio=0.5, \n                             solver=\"saga\")\nelastic.fit(X, Y)\n\n# Make predictions (class probabilities):\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogisticRegression(C=0.01, l1_ratio=0.5, multi_class='multinomial',\n                   penalty='elasticnet', solver='saga')\n```\n:::\n\n```{.python .cell-code}\nlasso.predict_proba(X)[0:10,:]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([[0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ],\n       [0.32460693, 0.34261077, 0.3327823 ]])\n```\n:::\n:::\n\n:::\n\n## Regression\n\n::: panel-tabset\n### R\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-5_85c57c8c46396516f4c3a04872c7bfa8'}\n\n```{.r .cell-code}\nX = scale(iris[,2:4])\nY = iris[,1]\n\n# Ridge:\nridge = glmnet(X, Y, family = gaussian(), alpha = 0, lambda = 0.01)\n\n# LASSO:\nlasso = glmnet(X, Y, family = gaussian(), alpha = 1, lambda = 0.01)\n\n# Elastic-net:\nelastic = glmnet(X, Y, family = gaussian(), alpha = 0.5, lambda = 0.01)\n```\n:::\n\n\nMake predictions (class probabilities):\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-6_1dd964d97e79e52b9ea5b14d5122be6e'}\n\n```{.r .cell-code}\nhead(predict(lasso, newx = X), n = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           s0\n[1,] 5.006484\n[2,] 4.720600\n[3,] 4.781548\n```\n:::\n:::\n\n\n### Python\n\nFor regressions we can use the ElasticNet model class, here, however, lambda corresponds to alpha and l1_ratio to the alpha parameter.\n\n\n::: {.cell hash='elastic_net_cache/html/unnamed-chunk-7_ff6db17efda0bd2c5cfca2b534bff51a'}\n\n```{.python .cell-code}\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn import datasets\nfrom sklearn.preprocessing import scale\niris = datasets.load_iris()\ndata = iris.data\nX = scale(data[:,1:4])\nY = data[:,0]\n\n\n# Ridge:\nridge = ElasticNet(alpha = 0.01,\n                   l1_ratio = 0.011)\nridge.fit(X, Y)\n\n# LASSO:\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nElasticNet(alpha=0.01, l1_ratio=0.011)\n```\n:::\n\n```{.python .cell-code}\nlasso = ElasticNet(alpha = 0.01,\n                   l1_ratio = 1.0)\nlasso.fit(X, Y)\n\n# Elastic-net:\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nElasticNet(alpha=0.01, l1_ratio=1.0)\n```\n:::\n\n```{.python .cell-code}\nelastic = ElasticNet(alpha = 0.01,\n                     l1_ratio = 0.5)\nelastic.fit(X, Y)\n\n# Make predictions:\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nElasticNet(alpha=0.01)\n```\n:::\n\n```{.python .cell-code}\nlasso.predict(X)[0:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\narray([5.0064384 , 4.72032938, 4.78125162, 4.83107256, 5.06366021,\n       5.36149937, 4.93202142, 5.00273797, 4.66310758, 4.84826774])\n```\n:::\n:::\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}