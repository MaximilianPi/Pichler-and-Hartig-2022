{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJXGBoostInterface ✔\n",
      "import MLJXGBoostInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/maximilianpichler/.julia/packages/MLJModels/kwZnx/src/loading.jl:168\n",
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/maximilianpichler/.julia/packages/MLJModels/kwZnx/src/loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJXGBoostInterface.XGBoostRegressor"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLJ\n",
    "using RDatasets\n",
    "using Pkg\n",
    "# Pkg.add(\"XGBoost\")\n",
    "# Pkg.add(\"MLJXGBoostInterface\")\n",
    "iris = dataset(\"datasets\", \"iris\")\n",
    "BRT_classifier = @load XGBoostClassifier pkg=XGBoost\n",
    "BRT_regressor =  @load XGBoostRegressor pkg=XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element CategoricalArrays.CategoricalArray{String,1,UInt8}:\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " ⋮\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const X = iris[:, 1:4]\n",
    "const Y = iris[:, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Response: Species -> 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{XGBoostClassifier,…}.\n",
      "└ @ MLJBase /Users/maximilianpichler/.julia/packages/MLJBase/hHa7b/src/machines.jl:464\n",
      "[1]\ttrain-mlogloss:0.736117\n",
      "[2]\ttrain-mlogloss:0.524235\n",
      "[3]\ttrain-mlogloss:0.387995\n",
      "[4]\ttrain-mlogloss:0.294146\n",
      "[5]\ttrain-mlogloss:0.226824\n",
      "[6]\ttrain-mlogloss:0.177835\n",
      "[7]\ttrain-mlogloss:0.141766\n",
      "[8]\ttrain-mlogloss:0.115003\n",
      "[9]\ttrain-mlogloss:0.094791\n",
      "[10]\ttrain-mlogloss:0.078860\n",
      "[11]\ttrain-mlogloss:0.066746\n",
      "[12]\ttrain-mlogloss:0.057845\n",
      "[13]\ttrain-mlogloss:0.050360\n",
      "[14]\ttrain-mlogloss:0.044290\n",
      "[15]\ttrain-mlogloss:0.039567\n",
      "[16]\ttrain-mlogloss:0.035267\n",
      "[17]\ttrain-mlogloss:0.032581\n",
      "[18]\ttrain-mlogloss:0.030403\n",
      "[19]\ttrain-mlogloss:0.028410\n",
      "[20]\ttrain-mlogloss:0.026969\n",
      "[21]\ttrain-mlogloss:0.025933\n",
      "[22]\ttrain-mlogloss:0.025456\n",
      "[23]\ttrain-mlogloss:0.024547\n",
      "[24]\ttrain-mlogloss:0.023938\n",
      "[25]\ttrain-mlogloss:0.023182\n",
      "[26]\ttrain-mlogloss:0.022793\n",
      "[27]\ttrain-mlogloss:0.022305\n",
      "[28]\ttrain-mlogloss:0.021978\n",
      "[29]\ttrain-mlogloss:0.021562\n",
      "[30]\ttrain-mlogloss:0.021312\n",
      "[31]\ttrain-mlogloss:0.020793\n",
      "[32]\ttrain-mlogloss:0.020556\n",
      "[33]\ttrain-mlogloss:0.020348\n",
      "[34]\ttrain-mlogloss:0.020017\n",
      "[35]\ttrain-mlogloss:0.019825\n",
      "[36]\ttrain-mlogloss:0.019623\n",
      "[37]\ttrain-mlogloss:0.019295\n",
      "[38]\ttrain-mlogloss:0.019071\n",
      "[39]\ttrain-mlogloss:0.018741\n",
      "[40]\ttrain-mlogloss:0.018543\n",
      "[41]\ttrain-mlogloss:0.018265\n",
      "[42]\ttrain-mlogloss:0.018117\n",
      "[43]\ttrain-mlogloss:0.017943\n",
      "[44]\ttrain-mlogloss:0.017812\n",
      "[45]\ttrain-mlogloss:0.017674\n",
      "[46]\ttrain-mlogloss:0.017545\n",
      "[47]\ttrain-mlogloss:0.017425\n",
      "[48]\ttrain-mlogloss:0.017313\n",
      "[49]\ttrain-mlogloss:0.017202\n",
      "[50]\ttrain-mlogloss:0.017058\n",
      "[51]\ttrain-mlogloss:0.016955\n",
      "[52]\ttrain-mlogloss:0.016852\n",
      "[53]\ttrain-mlogloss:0.016719\n",
      "[54]\ttrain-mlogloss:0.016627\n",
      "[55]\ttrain-mlogloss:0.016529\n",
      "[56]\ttrain-mlogloss:0.016440\n",
      "[57]\ttrain-mlogloss:0.016312\n",
      "[58]\ttrain-mlogloss:0.016224\n",
      "[59]\ttrain-mlogloss:0.016138\n",
      "[60]\ttrain-mlogloss:0.016018\n",
      "[61]\ttrain-mlogloss:0.015945\n",
      "[62]\ttrain-mlogloss:0.015839\n",
      "[63]\ttrain-mlogloss:0.015764\n",
      "[64]\ttrain-mlogloss:0.015699\n",
      "[65]\ttrain-mlogloss:0.015597\n",
      "[66]\ttrain-mlogloss:0.015527\n",
      "[67]\ttrain-mlogloss:0.015463\n",
      "[68]\ttrain-mlogloss:0.015365\n",
      "[69]\ttrain-mlogloss:0.015302\n",
      "[70]\ttrain-mlogloss:0.015211\n",
      "[71]\ttrain-mlogloss:0.015150\n",
      "[72]\ttrain-mlogloss:0.015059\n",
      "[73]\ttrain-mlogloss:0.014966\n",
      "[74]\ttrain-mlogloss:0.014914\n",
      "[75]\ttrain-mlogloss:0.014828\n",
      "[76]\ttrain-mlogloss:0.014776\n",
      "[77]\ttrain-mlogloss:0.014726\n",
      "[78]\ttrain-mlogloss:0.014649\n",
      "[79]\ttrain-mlogloss:0.014604\n",
      "[80]\ttrain-mlogloss:0.014530\n",
      "[81]\ttrain-mlogloss:0.014485\n",
      "[82]\ttrain-mlogloss:0.014419\n",
      "[83]\ttrain-mlogloss:0.014381\n",
      "[84]\ttrain-mlogloss:0.014302\n",
      "[85]\ttrain-mlogloss:0.014264\n",
      "[86]\ttrain-mlogloss:0.014229\n",
      "[87]\ttrain-mlogloss:0.014194\n",
      "[88]\ttrain-mlogloss:0.014160\n",
      "[89]\ttrain-mlogloss:0.014129\n",
      "[90]\ttrain-mlogloss:0.014094\n",
      "[91]\ttrain-mlogloss:0.014065\n",
      "[92]\ttrain-mlogloss:0.014033\n",
      "[93]\ttrain-mlogloss:0.014002\n",
      "[94]\ttrain-mlogloss:0.013976\n",
      "[95]\ttrain-mlogloss:0.013945\n",
      "[96]\ttrain-mlogloss:0.013918\n",
      "[97]\ttrain-mlogloss:0.013893\n",
      "[98]\ttrain-mlogloss:0.013869\n",
      "[99]\ttrain-mlogloss:0.013840\n",
      "[100]\ttrain-mlogloss:0.013815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{XGBoostClassifier,…} trained 1 time; caches data\n",
       "  model: MLJXGBoostInterface.XGBoostClassifier\n",
       "  args: \n",
       "    1:\tSource @165 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @224 ⏎ `AbstractVector{Multiclass{3}}`\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BRT_classifier()\n",
    "mach = machine(model, X, Y)\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element CategoricalDistributions.UnivariateFiniteVector{Multiclass{3}, String, UInt8, Float32}:\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.996, versicolor=>0.00238, virginica=>0.00126)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000822)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.996, versicolor=>0.00238, virginica=>0.00126)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000822)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.997, versicolor=>0.00238, virginica=>0.000814)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.996, versicolor=>0.00238, virginica=>0.00126)\n",
       " ⋮\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.00169, versicolor=>0.142, virginica=>0.856)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000417, versicolor=>0.00105, virginica=>0.999)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000417, versicolor=>0.00105, virginica=>0.999)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000956, versicolor=>0.00503, virginica=>0.994)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0019, versicolor=>0.00647, virginica=>0.992)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000484, versicolor=>0.00126, virginica=>0.998)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000484, versicolor=>0.00126, virginica=>0.998)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000328, versicolor=>0.00083, virginica=>0.999)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.00041, versicolor=>0.00185, virginica=>0.998)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000328, versicolor=>0.000742, virginica=>0.999)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.000447, versicolor=>0.00116, virginica=>0.998)\n",
       " UnivariateFinite{Multiclass{3}}(setosa=>0.0023, versicolor=>0.0162, virginica=>0.982)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mach, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Response: Sepal.Length -> continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{XGBoostRegressor,…}.\n",
      "└ @ MLJBase /Users/maximilianpichler/.julia/packages/MLJBase/hHa7b/src/machines.jl:464\n",
      "[1]\ttrain-rmse:3.822960\n",
      "[2]\ttrain-rmse:2.713300\n",
      "[3]\ttrain-rmse:1.938664\n",
      "[4]\ttrain-rmse:1.394237\n",
      "[5]\ttrain-rmse:1.015508\n",
      "[6]\ttrain-rmse:0.750811\n",
      "[7]\ttrain-rmse:0.568826\n",
      "[8]\ttrain-rmse:0.442090\n",
      "[9]\ttrain-rmse:0.355813\n",
      "[10]\ttrain-rmse:0.299644\n",
      "[11]\ttrain-rmse:0.262145\n",
      "[12]\ttrain-rmse:0.234975\n",
      "[13]\ttrain-rmse:0.217319\n",
      "[14]\ttrain-rmse:0.201071\n",
      "[15]\ttrain-rmse:0.185783\n",
      "[16]\ttrain-rmse:0.180621\n",
      "[17]\ttrain-rmse:0.170717\n",
      "[18]\ttrain-rmse:0.159421\n",
      "[19]\ttrain-rmse:0.145986\n",
      "[20]\ttrain-rmse:0.140951\n",
      "[21]\ttrain-rmse:0.135618\n",
      "[22]\ttrain-rmse:0.131288\n",
      "[23]\ttrain-rmse:0.121606\n",
      "[24]\ttrain-rmse:0.115585\n",
      "[25]\ttrain-rmse:0.113197\n",
      "[26]\ttrain-rmse:0.109322\n",
      "[27]\ttrain-rmse:0.106209\n",
      "[28]\ttrain-rmse:0.104738\n",
      "[29]\ttrain-rmse:0.095701\n",
      "[30]\ttrain-rmse:0.090648\n",
      "[31]\ttrain-rmse:0.089510\n",
      "[32]\ttrain-rmse:0.086384\n",
      "[33]\ttrain-rmse:0.085086\n",
      "[34]\ttrain-rmse:0.082552\n",
      "[35]\ttrain-rmse:0.078263\n",
      "[36]\ttrain-rmse:0.074063\n",
      "[37]\ttrain-rmse:0.073144\n",
      "[38]\ttrain-rmse:0.072752\n",
      "[39]\ttrain-rmse:0.072247\n",
      "[40]\ttrain-rmse:0.068102\n",
      "[41]\ttrain-rmse:0.064078\n",
      "[42]\ttrain-rmse:0.060641\n",
      "[43]\ttrain-rmse:0.060077\n",
      "[44]\ttrain-rmse:0.057789\n",
      "[45]\ttrain-rmse:0.057368\n",
      "[46]\ttrain-rmse:0.056932\n",
      "[47]\ttrain-rmse:0.054187\n",
      "[48]\ttrain-rmse:0.053684\n",
      "[49]\ttrain-rmse:0.052962\n",
      "[50]\ttrain-rmse:0.052108\n",
      "[51]\ttrain-rmse:0.050153\n",
      "[52]\ttrain-rmse:0.048504\n",
      "[53]\ttrain-rmse:0.046341\n",
      "[54]\ttrain-rmse:0.045868\n",
      "[55]\ttrain-rmse:0.045695\n",
      "[56]\ttrain-rmse:0.045012\n",
      "[57]\ttrain-rmse:0.044547\n",
      "[58]\ttrain-rmse:0.043998\n",
      "[59]\ttrain-rmse:0.043675\n",
      "[60]\ttrain-rmse:0.042691\n",
      "[61]\ttrain-rmse:0.041712\n",
      "[62]\ttrain-rmse:0.041323\n",
      "[63]\ttrain-rmse:0.041082\n",
      "[64]\ttrain-rmse:0.040615\n",
      "[65]\ttrain-rmse:0.040120\n",
      "[66]\ttrain-rmse:0.039805\n",
      "[67]\ttrain-rmse:0.038725\n",
      "[68]\ttrain-rmse:0.038449\n",
      "[69]\ttrain-rmse:0.038286\n",
      "[70]\ttrain-rmse:0.037273\n",
      "[71]\ttrain-rmse:0.037102\n",
      "[72]\ttrain-rmse:0.036297\n",
      "[73]\ttrain-rmse:0.036019\n",
      "[74]\ttrain-rmse:0.035652\n",
      "[75]\ttrain-rmse:0.035191\n",
      "[76]\ttrain-rmse:0.035120\n",
      "[77]\ttrain-rmse:0.034492\n",
      "[78]\ttrain-rmse:0.034410\n",
      "[79]\ttrain-rmse:0.034391\n",
      "[80]\ttrain-rmse:0.034269\n",
      "[81]\ttrain-rmse:0.034038\n",
      "[82]\ttrain-rmse:0.033984\n",
      "[83]\ttrain-rmse:0.033943\n",
      "[84]\ttrain-rmse:0.033927\n",
      "[85]\ttrain-rmse:0.033865\n",
      "[86]\ttrain-rmse:0.033833\n",
      "[87]\ttrain-rmse:0.033740\n",
      "[88]\ttrain-rmse:0.033695\n",
      "[89]\ttrain-rmse:0.033548\n",
      "[90]\ttrain-rmse:0.033452\n",
      "[91]\ttrain-rmse:0.033170\n",
      "[92]\ttrain-rmse:0.033063\n",
      "[93]\ttrain-rmse:0.033007\n",
      "[94]\ttrain-rmse:0.032835\n",
      "[95]\ttrain-rmse:0.032722\n",
      "[96]\ttrain-rmse:0.032533\n",
      "[97]\ttrain-rmse:0.032428\n",
      "[98]\ttrain-rmse:0.032292\n",
      "[99]\ttrain-rmse:0.032225\n",
      "[100]\ttrain-rmse:0.032121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{XGBoostRegressor,…} trained 1 time; caches data\n",
       "  model: MLJXGBoostInterface.XGBoostRegressor\n",
       "  args: \n",
       "    1:\tSource @145 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @489 ⏎ `AbstractVector{Continuous}`\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BRT_regressor()\n",
    "mach = machine(model, X[:,2:4], X[:,1])\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Vector{Float32}:\n",
       " 5.1509466\n",
       " 4.8569074\n",
       " 4.551141\n",
       " 4.7587333\n",
       " 4.999504\n",
       " 5.400946\n",
       " 4.618028\n",
       " 5.0595293\n",
       " 4.408353\n",
       " 4.8894806\n",
       " 5.3452225\n",
       " 4.8175235\n",
       " 4.8118615\n",
       " ⋮\n",
       " 5.9796143\n",
       " 6.895111\n",
       " 6.703877\n",
       " 6.896168\n",
       " 5.8010306\n",
       " 6.802212\n",
       " 6.699077\n",
       " 6.6998677\n",
       " 6.2977123\n",
       " 6.5002704\n",
       " 6.2019157\n",
       " 5.9145174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(mach, X[:,2:4])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2c8e16c7ccab309b6c7ff727be01f1772ce77360f8d9c2b6c3a69dbab5f4903"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
