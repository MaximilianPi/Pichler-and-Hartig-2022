{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X = (X - np.mean(X))/np.std(X)\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "Response: Species -> 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1210181713104248\n",
      "1.0183498859405518\n",
      "0.7089935541152954\n",
      "0.39600253105163574\n",
      "0.28598326444625854\n",
      "0.2722209095954895\n",
      "0.3285526633262634\n",
      "0.22217264771461487\n",
      "0.07098357379436493\n",
      "0.10444505512714386\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 3)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.Net(x)\n",
    "\n",
    "NN = Net()\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.long))\n",
    "DT = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "optim = torch.optim.Adamax(NN.parameters())\n",
    "\n",
    "for e in range(100):\n",
    "    for x, y in DT:\n",
    "        optim.zero_grad()\n",
    "        pred = NN.forward(x)\n",
    "        loss = torch.nn.functional.cross_entropy(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    if e%10 == 0:\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = NN.forward(torch.tensor(X, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.8932e-01, 1.0682e-02, 9.9086e-08],\n",
      "        [9.8605e-01, 1.3953e-02, 1.2701e-07],\n",
      "        [9.8959e-01, 1.0407e-02, 1.0176e-07],\n",
      "        [9.8699e-01, 1.3009e-02, 1.7625e-07],\n",
      "        [9.8945e-01, 1.0552e-02, 1.1009e-07],\n",
      "        [9.8478e-01, 1.5224e-02, 2.8323e-07],\n",
      "        [9.8788e-01, 1.2121e-02, 1.8922e-07],\n",
      "        [9.8819e-01, 1.1807e-02, 1.3034e-07],\n",
      "        [9.8760e-01, 1.2396e-02, 1.5807e-07],\n",
      "        [9.8593e-01, 1.4066e-02, 1.2858e-07],\n",
      "        [9.8832e-01, 1.1679e-02, 1.0682e-07],\n",
      "        [9.8712e-01, 1.2879e-02, 1.9141e-07],\n",
      "        [9.8763e-01, 1.2373e-02, 1.0152e-07],\n",
      "        [9.9084e-01, 9.1580e-03, 7.0760e-08],\n",
      "        [9.9147e-01, 8.5320e-03, 4.2687e-08],\n",
      "        [9.8841e-01, 1.1588e-02, 1.5844e-07],\n",
      "        [9.8932e-01, 1.0677e-02, 1.1469e-07],\n",
      "        [9.8850e-01, 1.1495e-02, 1.2736e-07],\n",
      "        [9.8265e-01, 1.7352e-02, 2.0907e-07],\n",
      "        [9.8807e-01, 1.1930e-02, 1.7094e-07],\n",
      "        [9.7910e-01, 2.0902e-02, 2.3527e-07],\n",
      "        [9.8704e-01, 1.2963e-02, 2.1322e-07],\n",
      "        [9.9083e-01, 9.1660e-03, 7.1865e-08],\n",
      "        [9.7651e-01, 2.3492e-02, 5.4170e-07],\n",
      "        [9.7951e-01, 2.0485e-02, 4.7726e-07],\n",
      "        [9.7840e-01, 2.1600e-02, 2.5187e-07],\n",
      "        [9.8450e-01, 1.5502e-02, 2.8187e-07],\n",
      "        [9.8804e-01, 1.1960e-02, 1.1783e-07],\n",
      "        [9.8871e-01, 1.1294e-02, 9.3206e-08],\n",
      "        [9.8575e-01, 1.4251e-02, 2.1416e-07],\n",
      "        [9.8328e-01, 1.6721e-02, 2.2756e-07],\n",
      "        [9.8342e-01, 1.6579e-02, 1.9485e-07],\n",
      "        [9.8964e-01, 1.0364e-02, 1.0732e-07],\n",
      "        [9.9019e-01, 9.8050e-03, 8.7770e-08],\n",
      "        [9.8507e-01, 1.4935e-02, 1.6263e-07],\n",
      "        [9.9038e-01, 9.6176e-03, 6.4962e-08],\n",
      "        [9.8912e-01, 1.0879e-02, 6.4817e-08],\n",
      "        [9.9000e-01, 9.9959e-03, 9.4014e-08],\n",
      "        [9.8913e-01, 1.0869e-02, 1.2374e-07],\n",
      "        [9.8772e-01, 1.2278e-02, 1.2589e-07],\n",
      "        [9.8937e-01, 1.0634e-02, 1.1103e-07],\n",
      "        [9.7454e-01, 2.5456e-02, 2.8874e-07],\n",
      "        [9.8901e-01, 1.0989e-02, 1.3433e-07],\n",
      "        [9.8321e-01, 1.6792e-02, 4.5061e-07],\n",
      "        [9.8184e-01, 1.8160e-02, 5.4110e-07],\n",
      "        [9.8605e-01, 1.3951e-02, 1.6242e-07],\n",
      "        [9.8805e-01, 1.1947e-02, 1.6439e-07],\n",
      "        [9.8868e-01, 1.1317e-02, 1.3708e-07],\n",
      "        [9.8871e-01, 1.1290e-02, 1.1136e-07],\n",
      "        [9.8888e-01, 1.1121e-02, 1.0281e-07],\n",
      "        [1.0359e-04, 7.5363e-01, 2.4627e-01],\n",
      "        [5.4609e-04, 8.3950e-01, 1.5995e-01],\n",
      "        [3.4553e-05, 5.6114e-01, 4.3882e-01],\n",
      "        [3.1645e-03, 9.7003e-01, 2.6806e-02],\n",
      "        [1.3301e-04, 7.5986e-01, 2.4001e-01],\n",
      "        [1.1740e-03, 9.0168e-01, 9.7142e-02],\n",
      "        [3.0920e-04, 7.0472e-01, 2.9497e-01],\n",
      "        [1.1918e-01, 8.7951e-01, 1.3162e-03],\n",
      "        [2.0041e-04, 8.4259e-01, 1.5721e-01],\n",
      "        [1.4498e-02, 9.6596e-01, 1.9540e-02],\n",
      "        [2.8652e-02, 9.6849e-01, 2.8618e-03],\n",
      "        [2.5200e-03, 9.3101e-01, 6.6471e-02],\n",
      "        [1.6428e-03, 9.8299e-01, 1.5363e-02],\n",
      "        [2.8449e-04, 7.8223e-01, 2.1748e-01],\n",
      "        [3.2010e-02, 9.6165e-01, 6.3420e-03],\n",
      "        [4.3822e-04, 8.8840e-01, 1.1116e-01],\n",
      "        [1.5234e-03, 8.6045e-01, 1.3802e-01],\n",
      "        [4.7160e-03, 9.7961e-01, 1.5676e-02],\n",
      "        [9.3852e-05, 7.8480e-01, 2.1510e-01],\n",
      "        [7.3344e-03, 9.8132e-01, 1.1346e-02],\n",
      "        [2.1322e-04, 5.3459e-01, 4.6519e-01],\n",
      "        [3.0584e-03, 9.7067e-01, 2.6274e-02],\n",
      "        [2.8339e-05, 5.4545e-01, 4.5452e-01],\n",
      "        [3.3355e-04, 8.5206e-01, 1.4761e-01],\n",
      "        [8.1939e-04, 9.3321e-01, 6.5968e-02],\n",
      "        [4.2549e-04, 8.8736e-01, 1.1221e-01],\n",
      "        [4.2080e-05, 6.7030e-01, 3.2966e-01],\n",
      "        [1.4389e-05, 3.6577e-01, 6.3422e-01],\n",
      "        [5.9835e-04, 8.3952e-01, 1.5989e-01],\n",
      "        [3.0463e-02, 9.6698e-01, 2.5536e-03],\n",
      "        [9.8009e-03, 9.8172e-01, 8.4812e-03],\n",
      "        [1.5446e-02, 9.7972e-01, 4.8347e-03],\n",
      "        [6.7371e-03, 9.7892e-01, 1.4342e-02],\n",
      "        [2.3136e-05, 3.7814e-01, 6.2183e-01],\n",
      "        [2.1850e-03, 8.6736e-01, 1.3045e-01],\n",
      "        [1.4369e-03, 8.3283e-01, 1.6573e-01],\n",
      "        [1.1808e-04, 7.1381e-01, 2.8607e-01],\n",
      "        [1.9937e-04, 8.9292e-01, 1.0688e-01],\n",
      "        [8.0403e-03, 9.6437e-01, 2.7589e-02],\n",
      "        [4.7677e-03, 9.7061e-01, 2.4622e-02],\n",
      "        [1.8247e-03, 9.3914e-01, 5.9031e-02],\n",
      "        [5.1207e-04, 8.3504e-01, 1.6445e-01],\n",
      "        [3.9830e-03, 9.7583e-01, 2.0184e-02],\n",
      "        [8.7162e-02, 9.1142e-01, 1.4154e-03],\n",
      "        [3.1356e-03, 9.5485e-01, 4.2011e-02],\n",
      "        [5.6388e-03, 9.6458e-01, 2.9783e-02],\n",
      "        [3.9636e-03, 9.5616e-01, 3.9881e-02],\n",
      "        [1.1703e-03, 9.3674e-01, 6.2086e-02],\n",
      "        [2.0138e-01, 7.9795e-01, 6.7224e-04],\n",
      "        [4.4772e-03, 9.6448e-01, 3.1042e-02],\n",
      "        [1.3105e-07, 2.2765e-02, 9.7723e-01],\n",
      "        [1.3206e-05, 2.3026e-01, 7.6972e-01],\n",
      "        [1.2243e-08, 1.5381e-02, 9.8462e-01],\n",
      "        [6.1637e-07, 7.3474e-02, 9.2653e-01],\n",
      "        [5.9386e-08, 2.0970e-02, 9.7903e-01],\n",
      "        [6.1488e-10, 6.8290e-03, 9.9317e-01],\n",
      "        [1.3063e-03, 7.8909e-01, 2.0961e-01],\n",
      "        [2.6055e-09, 1.1161e-02, 9.8884e-01],\n",
      "        [3.4145e-08, 3.3240e-02, 9.6676e-01],\n",
      "        [2.1991e-08, 1.4302e-02, 9.8570e-01],\n",
      "        [7.5152e-06, 1.8600e-01, 8.1400e-01],\n",
      "        [1.2524e-06, 1.1877e-01, 8.8123e-01],\n",
      "        [1.6248e-07, 4.2105e-02, 9.5789e-01],\n",
      "        [1.2419e-05, 2.2862e-01, 7.7137e-01],\n",
      "        [2.7788e-06, 7.9168e-02, 9.2083e-01],\n",
      "        [9.4422e-07, 5.6151e-02, 9.4385e-01],\n",
      "        [9.4440e-07, 9.4996e-02, 9.0500e-01],\n",
      "        [2.6464e-09, 8.5947e-03, 9.9141e-01],\n",
      "        [9.8024e-11, 4.5113e-03, 9.9549e-01],\n",
      "        [1.6053e-05, 4.6221e-01, 5.3778e-01],\n",
      "        [4.5958e-08, 1.9380e-02, 9.8062e-01],\n",
      "        [5.2650e-05, 3.2006e-01, 6.7989e-01],\n",
      "        [2.3517e-10, 5.6233e-03, 9.9438e-01],\n",
      "        [1.9386e-05, 3.7616e-01, 6.2382e-01],\n",
      "        [1.3126e-07, 2.8381e-02, 9.7162e-01],\n",
      "        [1.8986e-08, 2.0597e-02, 9.7940e-01],\n",
      "        [4.8491e-05, 4.6782e-01, 5.3213e-01],\n",
      "        [5.7221e-05, 4.2235e-01, 5.7759e-01],\n",
      "        [1.2392e-07, 3.2820e-02, 9.6718e-01],\n",
      "        [7.9047e-08, 5.3665e-02, 9.4633e-01],\n",
      "        [2.9845e-09, 1.2737e-02, 9.8726e-01],\n",
      "        [3.2321e-09, 9.4217e-03, 9.9058e-01],\n",
      "        [9.3484e-08, 2.7115e-02, 9.7289e-01],\n",
      "        [2.1718e-05, 4.2719e-01, 5.7279e-01],\n",
      "        [1.9461e-06, 1.7268e-01, 8.2731e-01],\n",
      "        [1.5272e-09, 8.4833e-03, 9.9152e-01],\n",
      "        [4.2434e-07, 3.1279e-02, 9.6872e-01],\n",
      "        [1.4790e-06, 1.0164e-01, 8.9835e-01],\n",
      "        [1.1220e-04, 5.0525e-01, 4.9464e-01],\n",
      "        [3.0919e-07, 5.6682e-02, 9.4332e-01],\n",
      "        [7.2436e-08, 2.1506e-02, 9.7849e-01],\n",
      "        [8.7364e-07, 8.1531e-02, 9.1847e-01],\n",
      "        [1.3206e-05, 2.3026e-01, 7.6972e-01],\n",
      "        [3.5040e-08, 1.7283e-02, 9.8272e-01],\n",
      "        [9.0543e-08, 2.1032e-02, 9.7897e-01],\n",
      "        [5.6827e-07, 6.2848e-02, 9.3715e-01],\n",
      "        [5.2065e-06, 2.4022e-01, 7.5977e-01],\n",
      "        [2.6218e-06, 1.3425e-01, 8.6575e-01],\n",
      "        [1.3283e-06, 4.9808e-02, 9.5019e-01],\n",
      "        [3.0511e-05, 2.9887e-01, 7.0110e-01]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.functional.softmax(pred,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "Response: Sepal.Length -> continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2916386127471924\n",
      "0.30858591198921204\n",
      "0.0590483620762825\n",
      "0.039184268563985825\n",
      "0.039229974150657654\n",
      "0.03206280618906021\n",
      "0.035786859691143036\n",
      "0.02563987299799919\n",
      "0.03576971963047981\n",
      "0.028240865096449852\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(3, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.Net(x)\n",
    "\n",
    "NN = Net()\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(torch.tensor(X[:,1:], dtype=torch.float32), torch.tensor(X[:,[0]], dtype=torch.float32))\n",
    "DT = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "\n",
    "optim = torch.optim.Adamax(NN.parameters())\n",
    "\n",
    "for e in range(100):\n",
    "    for x, y in DT:\n",
    "        optim.zero_grad()\n",
    "        pred = NN.forward(x)\n",
    "        loss = torch.nn.functional.mse_loss(pred, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    if e%10 == 0:\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = NN.forward(torch.tensor(X[:,1:], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7713],\n",
       "        [0.7427],\n",
       "        [0.7393],\n",
       "        [0.7609],\n",
       "        [0.7803],\n",
       "        [0.8094],\n",
       "        [0.7481],\n",
       "        [0.7758],\n",
       "        [0.7377],\n",
       "        [0.7773],\n",
       "        [0.8001],\n",
       "        [0.7891],\n",
       "        [0.7590],\n",
       "        [0.7191],\n",
       "        [0.7851],\n",
       "        [0.8028],\n",
       "        [0.7647],\n",
       "        [0.7571],\n",
       "        [0.8163],\n",
       "        [0.7948],\n",
       "        [0.8024],\n",
       "        [0.7715],\n",
       "        [0.7370],\n",
       "        [0.7485],\n",
       "        [0.8291],\n",
       "        [0.7693],\n",
       "        [0.7565],\n",
       "        [0.7821],\n",
       "        [0.7625],\n",
       "        [0.7792],\n",
       "        [0.7743],\n",
       "        [0.7446],\n",
       "        [0.8353],\n",
       "        [0.8146],\n",
       "        [0.7609],\n",
       "        [0.7260],\n",
       "        [0.7606],\n",
       "        [0.7946],\n",
       "        [0.7294],\n",
       "        [0.7758],\n",
       "        [0.7463],\n",
       "        [0.6783],\n",
       "        [0.7393],\n",
       "        [0.7357],\n",
       "        [0.8236],\n",
       "        [0.7263],\n",
       "        [0.8198],\n",
       "        [0.7526],\n",
       "        [0.8001],\n",
       "        [0.7575],\n",
       "        [1.4096],\n",
       "        [1.3335],\n",
       "        [1.4601],\n",
       "        [1.0845],\n",
       "        [1.3266],\n",
       "        [1.3069],\n",
       "        [1.4049],\n",
       "        [0.9069],\n",
       "        [1.3514],\n",
       "        [1.0841],\n",
       "        [0.9452],\n",
       "        [1.2103],\n",
       "        [1.0960],\n",
       "        [1.3784],\n",
       "        [1.0093],\n",
       "        [1.2963],\n",
       "        [1.3129],\n",
       "        [1.1819],\n",
       "        [1.2306],\n",
       "        [1.0854],\n",
       "        [1.4143],\n",
       "        [1.1359],\n",
       "        [1.3983],\n",
       "        [1.3827],\n",
       "        [1.2488],\n",
       "        [1.2860],\n",
       "        [1.4023],\n",
       "        [1.4694],\n",
       "        [1.3026],\n",
       "        [0.9661],\n",
       "        [1.0409],\n",
       "        [1.0140],\n",
       "        [1.0987],\n",
       "        [1.4800],\n",
       "        [1.3129],\n",
       "        [1.3468],\n",
       "        [1.3916],\n",
       "        [1.2213],\n",
       "        [1.1907],\n",
       "        [1.1050],\n",
       "        [1.2595],\n",
       "        [1.3544],\n",
       "        [1.1226],\n",
       "        [0.9073],\n",
       "        [1.1940],\n",
       "        [1.2336],\n",
       "        [1.2146],\n",
       "        [1.2488],\n",
       "        [0.8424],\n",
       "        [1.1701],\n",
       "        [1.7278],\n",
       "        [1.4582],\n",
       "        [1.7481],\n",
       "        [1.6571],\n",
       "        [1.7066],\n",
       "        [1.9876],\n",
       "        [1.2469],\n",
       "        [1.8966],\n",
       "        [1.6844],\n",
       "        [1.7539],\n",
       "        [1.5023],\n",
       "        [1.5266],\n",
       "        [1.6113],\n",
       "        [1.3961],\n",
       "        [1.4320],\n",
       "        [1.5373],\n",
       "        [1.6332],\n",
       "        [2.0002],\n",
       "        [2.0345],\n",
       "        [1.4017],\n",
       "        [1.6682],\n",
       "        [1.3927],\n",
       "        [2.0085],\n",
       "        [1.3970],\n",
       "        [1.7023],\n",
       "        [1.8248],\n",
       "        [1.3731],\n",
       "        [1.4279],\n",
       "        [1.6249],\n",
       "        [1.7504],\n",
       "        [1.8106],\n",
       "        [1.9383],\n",
       "        [1.6176],\n",
       "        [1.4976],\n",
       "        [1.6554],\n",
       "        [1.8020],\n",
       "        [1.6129],\n",
       "        [1.6435],\n",
       "        [1.3937],\n",
       "        [1.5874],\n",
       "        [1.6195],\n",
       "        [1.4701],\n",
       "        [1.4582],\n",
       "        [1.7336],\n",
       "        [1.6297],\n",
       "        [1.4941],\n",
       "        [1.4034],\n",
       "        [1.5159],\n",
       "        [1.5656],\n",
       "        [1.4963]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2c8e16c7ccab309b6c7ff727be01f1772ce77360f8d9c2b6c3a69dbab5f4903"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
